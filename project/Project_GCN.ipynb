{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40e72619",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "import scipy.sparse as sp\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.model_selection import KFold\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bedd39b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    adj = sp.load_npz('./data_2024/adj.npz')\n",
    "    features = np.load('./data_2024/features.npy')\n",
    "    labels = np.load('./data_2024/labels.npy')\n",
    "    with open('./data_2024/splits.json', 'r') as file:\n",
    "        splits = json.load(file)\n",
    "    idx_train, idx_test = splits['idx_train'], splits['idx_test']\n",
    "    # convert adjacency matrix to edge index\n",
    "    adj = adj.tocoo()\n",
    "    edge_index = np.vstack((adj.row, adj.col))\n",
    "\n",
    "    # normalize features\n",
    "    features = features / features.sum(1, keepdims=True)\n",
    "\n",
    "    # convert to tensors\n",
    "    edge_index = torch.tensor(edge_index, dtype=torch.long)\n",
    "    features = torch.tensor(features, dtype=torch.float)\n",
    "    labels = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "    # create torch geometric data object\n",
    "    data = Data(x=features, edge_index=edge_index, y=labels)\n",
    "\n",
    "    return data, torch.tensor(idx_train, dtype=torch.long), torch.tensor(idx_test, dtype=torch.long)\n",
    "\n",
    "data, idx_train, idx_test = load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2210c683",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: modify GCN architecture for better performance. Try derivatives of published architectures?\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, num_features, num_classes):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(num_features, 16)\n",
    "        self.conv2 = GCNConv(16, num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b9ce3f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1, Epoch 0: Loss 1.9459484815597534, Validation Accuracy: 0.28\n",
      "Fold 1, Epoch 10: Loss 1.7955107688903809, Validation Accuracy: 0.28\n",
      "Fold 1, Epoch 20: Loss 1.6562772989273071, Validation Accuracy: 0.28\n",
      "Fold 1, Epoch 30: Loss 1.4853079319000244, Validation Accuracy: 0.49\n",
      "Fold 1, Epoch 40: Loss 1.2850769758224487, Validation Accuracy: 0.63\n",
      "Fold 1, Epoch 50: Loss 1.0980970859527588, Validation Accuracy: 0.71\n",
      "Fold 1, Epoch 60: Loss 0.8571550846099854, Validation Accuracy: 0.79\n",
      "Fold 1, Epoch 70: Loss 0.7523890733718872, Validation Accuracy: 0.78\n",
      "Fold 1, Epoch 80: Loss 0.6127892732620239, Validation Accuracy: 0.82\n",
      "Fold 1, Epoch 90: Loss 0.5103626847267151, Validation Accuracy: 0.84\n",
      "Fold 1, Epoch 100: Loss 0.4417681396007538, Validation Accuracy: 0.84\n",
      "Fold 1, Epoch 110: Loss 0.3694544732570648, Validation Accuracy: 0.84\n",
      "Fold 1, Epoch 120: Loss 0.3411328196525574, Validation Accuracy: 0.84\n",
      "Fold 1, Epoch 130: Loss 0.2920863926410675, Validation Accuracy: 0.84\n",
      "Fold 1, Epoch 140: Loss 0.28077030181884766, Validation Accuracy: 0.83\n",
      "Fold 1, Epoch 150: Loss 0.2563709020614624, Validation Accuracy: 0.83\n",
      "Fold 1, Epoch 160: Loss 0.23298610746860504, Validation Accuracy: 0.84\n",
      "Fold 1, Epoch 170: Loss 0.22307606041431427, Validation Accuracy: 0.83\n",
      "Fold 1, Epoch 180: Loss 0.17158737778663635, Validation Accuracy: 0.82\n",
      "Fold 1, Epoch 190: Loss 0.16193066537380219, Validation Accuracy: 0.83\n",
      "Fold 2, Epoch 0: Loss 1.9452859163284302, Validation Accuracy: 0.2828282828282828\n",
      "Fold 2, Epoch 10: Loss 1.7886282205581665, Validation Accuracy: 0.2828282828282828\n",
      "Fold 2, Epoch 20: Loss 1.6454163789749146, Validation Accuracy: 0.2828282828282828\n",
      "Fold 2, Epoch 30: Loss 1.4577690362930298, Validation Accuracy: 0.5151515151515151\n",
      "Fold 2, Epoch 40: Loss 1.260321855545044, Validation Accuracy: 0.6262626262626263\n",
      "Fold 2, Epoch 50: Loss 1.0718566179275513, Validation Accuracy: 0.6767676767676768\n",
      "Fold 2, Epoch 60: Loss 0.8746313452720642, Validation Accuracy: 0.7777777777777778\n",
      "Fold 2, Epoch 70: Loss 0.7482662796974182, Validation Accuracy: 0.8181818181818182\n",
      "Fold 2, Epoch 80: Loss 0.6271478533744812, Validation Accuracy: 0.8080808080808081\n",
      "Fold 2, Epoch 90: Loss 0.533075749874115, Validation Accuracy: 0.8282828282828283\n",
      "Fold 2, Epoch 100: Loss 0.4509451985359192, Validation Accuracy: 0.8181818181818182\n",
      "Fold 2, Epoch 110: Loss 0.3981265127658844, Validation Accuracy: 0.8181818181818182\n",
      "Fold 2, Epoch 120: Loss 0.3202202618122101, Validation Accuracy: 0.8181818181818182\n",
      "Fold 2, Epoch 130: Loss 0.3092653155326843, Validation Accuracy: 0.8080808080808081\n",
      "Fold 2, Epoch 140: Loss 0.2694760859012604, Validation Accuracy: 0.8181818181818182\n",
      "Fold 2, Epoch 150: Loss 0.24370907247066498, Validation Accuracy: 0.7878787878787878\n",
      "Fold 2, Epoch 160: Loss 0.23598475754261017, Validation Accuracy: 0.7878787878787878\n",
      "Fold 2, Epoch 170: Loss 0.21796204149723053, Validation Accuracy: 0.797979797979798\n",
      "Fold 2, Epoch 180: Loss 0.1995789110660553, Validation Accuracy: 0.797979797979798\n",
      "Fold 2, Epoch 190: Loss 0.168205127120018, Validation Accuracy: 0.7878787878787878\n",
      "Fold 3, Epoch 0: Loss 1.9463706016540527, Validation Accuracy: 0.32323232323232326\n",
      "Fold 3, Epoch 10: Loss 1.8015466928482056, Validation Accuracy: 0.29292929292929293\n",
      "Fold 3, Epoch 20: Loss 1.6495630741119385, Validation Accuracy: 0.30303030303030304\n",
      "Fold 3, Epoch 30: Loss 1.4891506433486938, Validation Accuracy: 0.43434343434343436\n",
      "Fold 3, Epoch 40: Loss 1.2837432622909546, Validation Accuracy: 0.5959595959595959\n",
      "Fold 3, Epoch 50: Loss 1.0705827474594116, Validation Accuracy: 0.6464646464646465\n",
      "Fold 3, Epoch 60: Loss 0.8835600018501282, Validation Accuracy: 0.6868686868686869\n",
      "Fold 3, Epoch 70: Loss 0.7299578189849854, Validation Accuracy: 0.7474747474747475\n",
      "Fold 3, Epoch 80: Loss 0.5987437963485718, Validation Accuracy: 0.7575757575757576\n",
      "Fold 3, Epoch 90: Loss 0.5004476308822632, Validation Accuracy: 0.7575757575757576\n",
      "Fold 3, Epoch 100: Loss 0.42241454124450684, Validation Accuracy: 0.7676767676767676\n",
      "Fold 3, Epoch 110: Loss 0.35211125016212463, Validation Accuracy: 0.7575757575757576\n",
      "Fold 3, Epoch 120: Loss 0.29778769612312317, Validation Accuracy: 0.7676767676767676\n",
      "Fold 3, Epoch 130: Loss 0.25851574540138245, Validation Accuracy: 0.7676767676767676\n",
      "Fold 3, Epoch 140: Loss 0.21479380130767822, Validation Accuracy: 0.7878787878787878\n",
      "Fold 3, Epoch 150: Loss 0.20665161311626434, Validation Accuracy: 0.7676767676767676\n",
      "Fold 3, Epoch 160: Loss 0.1647564023733139, Validation Accuracy: 0.7777777777777778\n",
      "Fold 3, Epoch 170: Loss 0.16624528169631958, Validation Accuracy: 0.7676767676767676\n",
      "Fold 3, Epoch 180: Loss 0.15852297842502594, Validation Accuracy: 0.7878787878787878\n",
      "Fold 3, Epoch 190: Loss 0.15855616331100464, Validation Accuracy: 0.7777777777777778\n",
      "Fold 4, Epoch 0: Loss 1.94679856300354, Validation Accuracy: 0.32323232323232326\n",
      "Fold 4, Epoch 10: Loss 1.8150711059570312, Validation Accuracy: 0.30303030303030304\n",
      "Fold 4, Epoch 20: Loss 1.6650968790054321, Validation Accuracy: 0.26262626262626265\n",
      "Fold 4, Epoch 30: Loss 1.4865796566009521, Validation Accuracy: 0.37373737373737376\n",
      "Fold 4, Epoch 40: Loss 1.316896677017212, Validation Accuracy: 0.6363636363636364\n",
      "Fold 4, Epoch 50: Loss 1.1026159524917603, Validation Accuracy: 0.6666666666666666\n",
      "Fold 4, Epoch 60: Loss 0.9209850430488586, Validation Accuracy: 0.6767676767676768\n",
      "Fold 4, Epoch 70: Loss 0.7902005910873413, Validation Accuracy: 0.7171717171717171\n",
      "Fold 4, Epoch 80: Loss 0.6393583416938782, Validation Accuracy: 0.7676767676767676\n",
      "Fold 4, Epoch 90: Loss 0.5519244074821472, Validation Accuracy: 0.8181818181818182\n",
      "Fold 4, Epoch 100: Loss 0.45060601830482483, Validation Accuracy: 0.8383838383838383\n",
      "Fold 4, Epoch 110: Loss 0.42036154866218567, Validation Accuracy: 0.8585858585858586\n",
      "Fold 4, Epoch 120: Loss 0.3350071609020233, Validation Accuracy: 0.8686868686868687\n",
      "Fold 4, Epoch 130: Loss 0.32399865984916687, Validation Accuracy: 0.8686868686868687\n",
      "Fold 4, Epoch 140: Loss 0.2974426746368408, Validation Accuracy: 0.8686868686868687\n",
      "Fold 4, Epoch 150: Loss 0.24363182485103607, Validation Accuracy: 0.8686868686868687\n",
      "Fold 4, Epoch 160: Loss 0.22346815466880798, Validation Accuracy: 0.8787878787878788\n",
      "Fold 4, Epoch 170: Loss 0.22014965116977692, Validation Accuracy: 0.8686868686868687\n",
      "Fold 4, Epoch 180: Loss 0.2013072669506073, Validation Accuracy: 0.8787878787878788\n",
      "Fold 4, Epoch 190: Loss 0.1918892115354538, Validation Accuracy: 0.8787878787878788\n",
      "Fold 5, Epoch 0: Loss 1.9454270601272583, Validation Accuracy: 0.16161616161616163\n",
      "Fold 5, Epoch 10: Loss 1.8084864616394043, Validation Accuracy: 0.42424242424242425\n",
      "Fold 5, Epoch 20: Loss 1.6683971881866455, Validation Accuracy: 0.41414141414141414\n",
      "Fold 5, Epoch 30: Loss 1.501461148262024, Validation Accuracy: 0.5757575757575758\n",
      "Fold 5, Epoch 40: Loss 1.3158931732177734, Validation Accuracy: 0.7171717171717171\n",
      "Fold 5, Epoch 50: Loss 1.0630061626434326, Validation Accuracy: 0.7171717171717171\n",
      "Fold 5, Epoch 60: Loss 0.8722553253173828, Validation Accuracy: 0.7878787878787878\n",
      "Fold 5, Epoch 70: Loss 0.7137301564216614, Validation Accuracy: 0.797979797979798\n",
      "Fold 5, Epoch 80: Loss 0.6098049283027649, Validation Accuracy: 0.7878787878787878\n",
      "Fold 5, Epoch 90: Loss 0.4854690730571747, Validation Accuracy: 0.8181818181818182\n",
      "Fold 5, Epoch 100: Loss 0.42239534854888916, Validation Accuracy: 0.8484848484848485\n",
      "Fold 5, Epoch 110: Loss 0.35478833317756653, Validation Accuracy: 0.8686868686868687\n",
      "Fold 5, Epoch 120: Loss 0.32491254806518555, Validation Accuracy: 0.8686868686868687\n",
      "Fold 5, Epoch 130: Loss 0.29561707377433777, Validation Accuracy: 0.8787878787878788\n",
      "Fold 5, Epoch 140: Loss 0.23634740710258484, Validation Accuracy: 0.8787878787878788\n",
      "Fold 5, Epoch 150: Loss 0.20310093462467194, Validation Accuracy: 0.8787878787878788\n",
      "Fold 5, Epoch 160: Loss 0.22024014592170715, Validation Accuracy: 0.8787878787878788\n",
      "Fold 5, Epoch 170: Loss 0.17980699241161346, Validation Accuracy: 0.8787878787878788\n",
      "Fold 5, Epoch 180: Loss 0.18517011404037476, Validation Accuracy: 0.8686868686868687\n",
      "Fold 5, Epoch 190: Loss 0.16143319010734558, Validation Accuracy: 0.8686868686868687\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# full set of labels with a default value (-1)\n",
    "full_labels = torch.full((2480,), -1, dtype=torch.long)\n",
    "full_labels[idx_train] = data.y\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "fold = 0 # folds for training (do NOT apply for testing)\n",
    "\n",
    "avg_training_losses = [] # lists for saving results\n",
    "avg_validation_accuracies = []\n",
    "\n",
    "best_validation_accuracy = 0 # initial objects\n",
    "best_model_state = None\n",
    "\n",
    "for train_index, val_index in kf.split(idx_train.numpy()):\n",
    "    fold += 1 # increase counter\n",
    "    model = GCN(num_features=1390, num_classes=7)\n",
    "    optimizer = Adam(model.parameters(), lr=0.01)\n",
    "    \n",
    "    training_losses = [] # more lists for storage\n",
    "    validation_accuracies = []\n",
    "    \n",
    "    for epoch in range(200):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        # compute loss on the training part\n",
    "        train_mask = full_labels[idx_train[train_index]] != -1\n",
    "        loss = F.nll_loss(out[idx_train[train_index]][train_mask], full_labels[idx_train[train_index]][train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        training_losses.append(loss.item())\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad(): # no gradient on validation\n",
    "            # validation accuracy\n",
    "            out = model(data)\n",
    "            _, pred = out.max(1)\n",
    "            val_mask = full_labels[idx_train[val_index]] != -1  # Ensure valid labels for val subset\n",
    "            correct = pred[idx_train[val_index]][val_mask].eq(full_labels[idx_train[val_index]][val_mask]).sum().item()\n",
    "            accuracy = correct / val_mask.sum().item()\n",
    "            validation_accuracies.append(accuracy)\n",
    "\n",
    "            if accuracy > best_validation_accuracy:\n",
    "                best_validation_accuracy = accuracy\n",
    "                best_model_state = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            print(f'Fold {fold}, Epoch {epoch}: Loss {loss.item()}, Validation Accuracy: {accuracy}')\n",
    "    #TODO: add early stopping?\n",
    "    avg_training_losses.append(np.mean(training_losses))\n",
    "    avg_validation_accuracies.append(np.mean(validation_accuracies))\n",
    "\n",
    "# load the best model state\n",
    "model.load_state_dict(best_model_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5c51e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now run model on true testing data\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    out = model(data)\n",
    "    _, pred = out.max(1)\n",
    "    test_labels_pred = pred[idx_test].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf5f0149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write out results\n",
    "submission_file_path = 'submission.txt'\n",
    "with open(submission_file_path, 'w') as file:\n",
    "    for label in test_labels_pred:\n",
    "        file.write(f'{label}\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
